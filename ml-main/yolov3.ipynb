{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of using YoloV3 to detect birds in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as tvm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sklearn.metrics as skms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YoloV3 is an object detection model developed by Joseph Redmon and Farhadi Ali\n",
    "\n",
    "@article{yolov3, title={YOLOv3: An Incremental Improvement}, author={Redmon, Joseph and Farhadi, Ali}, journal = {arXiv}, year={2018} } \n",
    "\n",
    "We used it to detect birds in our image and then identify their species using Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_output_layers(net):\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    try:\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except:\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "\n",
    "def draw_final_prediction(img, label, x, y, x_plus_w, y_plus_h):\n",
    "\n",
    "    color = (0,0,0)\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'testbrd12.jpg'\n",
    "classes_path = 'yolov3.txt'\n",
    "weights = 'yolov3.weights'\n",
    "config = 'yolov3.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    " '01.Mourning Dove',\n",
    " '02.Common Grackle',\n",
    " '03.Cardinal',\n",
    " '04.American Goldfinch',\n",
    " '05.Blue Jay',\n",
    " '06.White Breasted Nuthatch',\n",
    " '07.House Sparrow',\n",
    " '08.Red Bellied Woodpecker',\n",
    " '09.Downy Woodpecker',\n",
    " '10.Red Winged Black Bird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image)\n",
    "untouched_image = copy.deepcopy(image)\n",
    "Width = image.shape[1]\n",
    "Height = image.shape[0]\n",
    "scale = 0.00392\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(classes_path, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "net = cv2.dnn.readNet(weights, config)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "outs = net.forward(get_output_layers(net))\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])\n",
    "\n",
    "\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "# print(\"confidence is \",confidences)\n",
    "newi = [] # To save whichever boxes do not end outside our image\n",
    "for i in indices:\n",
    "    try:\n",
    "        box = boxes[i]\n",
    "    except:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "    \n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "\n",
    "    ## TODO: Fix the rectngular box exiting the image.\n",
    "\n",
    "    if x < 0 or y < 0 or w < 0 or h < 0: # If box ends outside the image, leave it\n",
    "        continue\n",
    "    draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "    newi.append(i)\n",
    "    \n",
    "cv2.imwrite(\"object-detection.jpg\", image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newimages = [] # To store partial images identified by YoloV3\n",
    "for i in newi:\n",
    "    x,y,w,h = boxes[i][0],boxes[i][1],boxes[i][2],boxes[i][3]\n",
    "    nx = round(x)\n",
    "    ny = round(y)\n",
    "    nw = round(w)\n",
    "    nh = round(h)\n",
    "    newimages.append((nx,ny,round(x+w),round(y+h)))\n",
    "    # newimages.append(image[ny:round(y+h),nx:round(x+w)])\n",
    "    #  cv2.imwrite(\"new.jpg\", newimages[0])  newimages stores both individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = tvm.resnet50()\n",
    "\n",
    "IN_FEATURES = md.fc.in_features \n",
    "OUTPUT_DIM = 10\n",
    "\n",
    "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
    "md.fc = fc\n",
    "\n",
    "\n",
    "md.load_state_dict(torch.load(\"birdmd1.pth\")) # Load model trained in NewBirds.ipnyb\n",
    "md.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranformation must be different when training and testing. Needs to be more rigorous when training\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(255),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allimagespic = [] # to display images later\n",
    "nt = copy.deepcopy(untouched_image)\n",
    "\n",
    "for img in newimages:\n",
    "    \n",
    "    newimg = image[img[1]:img[3],img[0]:img[2]]  #newimages.append((nx,ny,round(x+w),round(y+h)))\n",
    "\n",
    "    newimg1 = cv2.cvtColor(newimg, cv2.COLOR_BGR2RGB) # Matplotlib takes RGB while Opencv take BGR\n",
    "    allimagespic.append(newimg1)\n",
    "    cv2.imwrite(\"newtemp.jpg\", newimg)\n",
    "    nimg = Image.open(\"newtemp.jpg\").convert('RGB')\n",
    "    tr = test_transform(nimg)\n",
    "    tr = tr.unsqueeze(0)\n",
    "\n",
    "    logits = md(tr)\n",
    "    pred_probab = nn.Softmax(dim=1)(logits)\n",
    "    # print(pred_probab) # Test code\n",
    "    y_pred = pred_probab.argmax(1)\n",
    "    finalpred = class_names[np.argmax(pred_probab.detach().numpy())]\n",
    "    draw_final_prediction(nt,finalpred,img[0],img[1],img[2],img[3]) # Final image produced\n",
    "    print(f\"Predicted class: {finalpred}\")\n",
    "    # plt.imshow(nt) # Test Code\n",
    "cv2.imwrite(\"finalimg.jpg\", nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(allimagespic)\n",
    "fig = plt.figure(figsize=(8, 8))  # width, height in inches\n",
    "\n",
    "for i in range(0, n):\n",
    "    img = allimagespic[i]\n",
    "    fig.add_subplot(1, n, i+1)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
